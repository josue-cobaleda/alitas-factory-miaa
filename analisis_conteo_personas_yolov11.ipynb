{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4abaf13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Modelo cargado correctamente: yolo11s.pt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# %pip install ultralytics opencv-python pandas matplotlib tqdm\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from ultralytics import YOLO\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configura las rutas\n",
    "input_dir = \"videos\"       # üìÇ carpeta con los videos a analizar\n",
    "output_dir = \"resultados\"  # üìÇ carpeta donde se guardar√°n los resultados\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Par√°metros del modelo\n",
    "model_name = \"yolo11s.pt\"  # Puedes usar yolo11n.pt (r√°pido) o yolo11m/l/x.pt (m√°s preciso)\n",
    "conf_thres = 0.25          # Umbral de confianza\n",
    "device = \"cpu\"             # Usa \"cuda\" si tienes GPU\n",
    "use_tracking = True        # Activa tracking para IDs √∫nicos\n",
    "\n",
    "# Cargar modelo YOLOv11\n",
    "model = YOLO(model_name)\n",
    "print(\"‚úÖ Modelo cargado correctamente:\", model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d86e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def procesar_video(video_path, model, output_dir,\n",
    "                   conf=0.25, device=\"cpu\",\n",
    "                   use_tracking=True, save_annotated=False,\n",
    "                   frame_skip=28,  # üîπ procesa 1 de cada 5 frames\n",
    "                   max_frames=None  # üîπ l√≠mite opcional de frames (None = todos)\n",
    "                   ):\n",
    "    \"\"\"\n",
    "    Procesa un video largo con muestreo de frames y tracking opcional.\n",
    "    Guarda m√©tricas resumidas sin saturar memoria.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"‚ùå No se pudo abrir: {video_path}\")\n",
    "        return None\n",
    "\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) or 25.0\n",
    "    w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    base_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "    out_path = os.path.join(output_dir, f\"{base_name}_annotated-sg2.mp4\") if save_annotated else None\n",
    "\n",
    "    writer = None\n",
    "    if save_annotated:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "        writer = cv2.VideoWriter(out_path, fourcc, fps, (w, h))\n",
    "\n",
    "    print(f\"üé• Procesando: {base_name} ({total_frames} frames aprox.)\")\n",
    "    print(f\"‚öôÔ∏è  Procesando 1 de cada {frame_skip} frames para optimizar rendimiento\")\n",
    "\n",
    "    frame_id = 0\n",
    "    total_personas = 0\n",
    "    max_concurrent = 0\n",
    "    unique_ids = set()\n",
    "    processed_frames = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame_id += 1\n",
    "\n",
    "        # Saltar frames seg√∫n el muestreo\n",
    "        if frame_id % frame_skip != 0:\n",
    "            continue\n",
    "\n",
    "        # Limitar cantidad total procesada (√∫til para pruebas)\n",
    "        if max_frames and processed_frames >= max_frames:\n",
    "            break\n",
    "\n",
    "        results = model.predict(frame, conf=conf, device=device, classes=[0], verbose=False)\n",
    "\n",
    "        count = 0\n",
    "        if results and len(results[0].boxes) > 0:\n",
    "            for b in results[0].boxes:\n",
    "                if int(b.cls[0]) == 0:\n",
    "                    count += 1\n",
    "                    if use_tracking and hasattr(b, \"id\") and b.id is not None and len(b.id) > 0:\n",
    "                        unique_ids.add(int(b.id[0]))\n",
    "\n",
    "        total_personas += count\n",
    "        max_concurrent = max(max_concurrent, count)\n",
    "        processed_frames += 1\n",
    "\n",
    "        # Guardar video anotado opcionalmente\n",
    "        if save_annotated:\n",
    "            annotated = results[0].plot()\n",
    "            writer.write(annotated)\n",
    "\n",
    "        # Liberar memoria del frame\n",
    "        del results, frame\n",
    "\n",
    "    cap.release()\n",
    "    if writer:\n",
    "        writer.release()\n",
    "\n",
    "    return {\n",
    "        \"video\": base_name,\n",
    "        \"frames_totales\": total_frames,\n",
    "        \"frames_procesados\": processed_frames,\n",
    "        \"fps\": round(fps, 2),\n",
    "        \"muestreo\": frame_skip,\n",
    "        \"sum_persons_over_frames\": total_personas,\n",
    "        \"max_concurrent_persons\": max_concurrent,\n",
    "        \"unique_ids\": len(unique_ids) if use_tracking else None,\n",
    "        \"annotated_path\": out_path if save_annotated else None\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3f81b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se encontraron 1 videos para analizar.\n",
      "üé• Procesando: video (9005 frames aprox.)\n",
      "‚öôÔ∏è  Procesando 1 de cada 28 frames para optimizar rendimiento\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 3Ô∏è‚É£ Procesar todos los videos de una carpeta\n",
    "# ============================================\n",
    "\n",
    "def listar_videos(carpeta):\n",
    "    exts = (\".mp4\", \".avi\", \".mov\", \".mkv\", \".webm\")\n",
    "    return [os.path.join(carpeta, f) for f in os.listdir(carpeta) if f.endswith(exts)]\n",
    "\n",
    "videos = listar_videos(input_dir)\n",
    "if not videos:\n",
    "    print(\"‚ö†Ô∏è No se encontraron videos en la carpeta:\", input_dir)\n",
    "else:\n",
    "    print(f\"Se encontraron {len(videos)} videos para analizar.\")\n",
    "\n",
    "resultados = []\n",
    "for v in videos:\n",
    "    r = procesar_video(v, model, output_dir, conf_thres, device, use_tracking, save_annotated=True)\n",
    "    if r:\n",
    "        resultados.append(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92fb6f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ An√°lisis completado.\n",
      "üìÑ Resultados guardados en: resultados/resumen_conteo_personas_muestra-s2.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video</th>\n",
       "      <th>frames_totales</th>\n",
       "      <th>frames_procesados</th>\n",
       "      <th>fps</th>\n",
       "      <th>muestreo</th>\n",
       "      <th>sum_persons_over_frames</th>\n",
       "      <th>max_concurrent_persons</th>\n",
       "      <th>unique_ids</th>\n",
       "      <th>annotated_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>video</td>\n",
       "      <td>9005</td>\n",
       "      <td>321</td>\n",
       "      <td>30.0</td>\n",
       "      <td>28</td>\n",
       "      <td>3640</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>resultados/video_annotated-sg2.mp4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   video  frames_totales  frames_procesados   fps  muestreo  \\\n",
       "0  video            9005                321  30.0        28   \n",
       "\n",
       "   sum_persons_over_frames  max_concurrent_persons  unique_ids  \\\n",
       "0                     3640                      16           0   \n",
       "\n",
       "                       annotated_path  \n",
       "0  resultados/video_annotated-sg2.mp4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================\n",
    "# 4Ô∏è‚É£ Exportar resultados a CSV y mostrar resumen\n",
    "# ============================================\n",
    "\n",
    "df = pd.DataFrame(resultados)\n",
    "csv_path = os.path.join(output_dir, \"resumen_conteo_personas_muestra-s2.csv\")\n",
    "df.to_csv(csv_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"\\n‚úÖ An√°lisis completado.\")\n",
    "print(\"üìÑ Resultados guardados en:\", csv_path)\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bcdab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 5Ô∏è‚É£ Visualizaci√≥n r√°pida (opcional)\n",
    "# ============================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if not df.empty:\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.bar(df[\"video\"], df[\"max_concurrent_persons\"], color=\"skyblue\")\n",
    "    plt.title(\"Pico simult√°neo de personas por video\")\n",
    "    plt.ylabel(\"N√∫mero m√°ximo de personas\")\n",
    "    plt.xlabel(\"Video\")\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No hay datos para graficar.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_Taller_Video",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
